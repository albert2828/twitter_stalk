---
title: "Me stalkee en Twitter"
author: "Alberto Macías"
date: "6/7/2021"
output: html_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE, include=FALSE, message = FALSE, warning = FALSE,
                      fig.align='center')
```

```{r}
library(dplyr)
library(lubridate)
library(ggplot2)
library(gridExtra)

library(tidytext)
library(twitteR)
library(tm)
library(tokenizers)
library(wordcloud)
library(RColorBrewer)
```

A veces me stalkeo, para acordarme quién soy. Este ha sido uno de mis tuits más populares, desde hace ya casi cuatro años y, en cierta forma, sigo creyendo en eso. A lo que me refiero es que muchos acostumbramos compartir lo que sentimos o pensamos, de casi cualquier cosa, en redes sociales y, de vez en cuando, es buena idea revisar lo que escribimos para recordar quiénes hemos sido y evaluar cómo hemos cambiado. La etimología de "recordar" es algo como "volver a pasar por el corazón" y no sé ustedes, pero yo creo que de vez en cuando es bueno releer las angustias y los desamores, o el entusiasmo y la alegría, para saber dónde hemos estado y hacia dónde vamos. Ya lo dijo Heráclito, un hombre no escribe el mismo tuits dos veces, porque ya no es el mismo hombre ni el mismo tuit. O algo sobre ríos, ya no me acuerdo.

Una vez planteada esta premisa, quedan dos alternativas: pasar un par de horas haciendo scroll en nuestro perfil de Twitter o pasar un par de horas escribiendo código y descubrir algunos datos interesantes. Dado que tengo que aprender sobre procesamiento del lenguaje natural en R y con eso de que "debemos ser productivos", he optado por la segunda.

Para este texto, ocuparé la librería <em>twitterR\em> para descargar datos de mis últimos 1000 tuits publicados. Para poder hacer esto, es necesario tener una cuenta de desarrollador de twitter y crear una API con ella. Esto lo pueden hacer [aquí](https://developer.twitter.com/en), tendrán que llenar algunos datos y después de un día les llegará un correo con la autorización de su cuenta de desarrollador.

```{r}
tuits <- userTimeline("bhherto95",n=3200, includeRts = T) 
tuits <- twListToDF(tuits)
tuits_df <- tuits %>% filter(!isRetweet) %>%
            select(text, favoriteCount, replyToSN, id, created, retweetCount)
tuits_df$created <- with_tz(tuits_df$created, "America/Mexico_City")
```
Por alguna razón que no acabo de comprender, si no incluyo los retuits y luego los excluyo del data frame solo puedo descargar 37 tuits


- Distribución de favs y retuits  
- Serie temporal de favs y retuits  
- Análisis de las palabras que más tuiteo  
- Limpieza del corpus
- Análisis de los tuits con más favs y retuits  

```{r}
tuits_df %>% ggplot(aes(x=favoriteCount))+
            geom_histogram(binwidth = 1, color="black")+
            theme_minimal()+
            labs(title="Distribución de favs en tuits",
                 x="Número de Favs",
                 y="")
```


```{r}
summary(tuits_df$favoriteCount)
table(tuits_df$favoriteCount)
```

```{r}
tuits_df[tuits_df$favoriteCount==86,]$text
tuits_df[tuits_df$favoriteCount==48,]$text
tuits_df[tuits_df$favoriteCount==18,]$text
tuits_df[tuits_df$favoriteCount==17,]$text
```

```{r}
tuits_df %>% ggplot(aes(x=retweetCount))+
            geom_histogram(binwidth = 1, color="black")+
            theme_minimal()+
            labs(title="Distribución de retuits",
                 x="Número de retuits",
                 y="")
```

```{r}
summary(tuits_df$retweetCount)
table(tuits_df$retweetCount)
```

```{r}
tuits_df <- tuits_df %>% filter(favoriteCount<20)
```


```{r}
tuits_df %>% mutate(fecha=as.Date(created)) %>% 
            group_by(fecha) %>% summarise(tuits = n()) %>%
            ggplot(aes(x=fecha, y=tuits))+
            geom_line()+
            theme_light()+
            labs(title = "Número de tuits por día",
                 x="",
                 y="")+
            scale_x_date(date_labels = "%Y %b %d", date_breaks = "1 month")+
            theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
tuits_df %>% mutate(fecha=as.Date(created)) %>%
            filter(fecha >= as.Date("2020-03-01") & fecha <= as.Date("2020-05-01"))%>%
            group_by(fecha) %>% summarise(tuits = n()) %>%
            ggplot(aes(x=fecha, y=tuits))+
            geom_line()+
            theme_light()+
            labs(title = "Número de tuits por día: marzo a mayo 2020",
                 x="",
                 y="")+
            scale_x_date(date_labels = "%Y %b %d", date_breaks = "2 day")+
            theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
tuits_df %>% mutate(fecha=as.Date(created)) %>%
            filter(fecha== as.Date("2020-03-30") ) %>%
            select(text, replyToSN)
```


```{r}
tuits_df %>% mutate(fecha=as.Date(created)) %>% 
            group_by(fecha) %>% summarise(favs = sum(favoriteCount)) %>%
            ggplot(aes(x=fecha, y=favs))+
            geom_line()+
            theme_light()+
            labs(title = "Evolución del número de favs por día")
```

```{r}
tuits_df %>% filter(created>=as.Date("2021-01-01")) %>%
            mutate(fecha=as.Date(created)) %>% 
            group_by(fecha) %>% summarise(favs = sum(favoriteCount)) %>%
            ggplot(aes(x=fecha, y=favs))+
            geom_line()+
            theme_light()+
            labs(title="Evolución del número de favs por día en 2021")
```

```{r}
tuits_df %>% filter(created>=as.Date("2021-01-01")) %>%
            mutate(fecha=as.Date(created)) %>% 
            group_by(fecha) %>% summarise(tuits = n()) %>%
            ggplot(aes(x=fecha, y=tuits))+
            geom_line()+
            theme_light()+
            labs(title="Tuits por día en 2021")
```

```{r}
tuits_df %>% mutate(dia = wday(created, label = TRUE)) %>%
            group_by(dia) %>% 
            summarise(favs = sum(favoriteCount)) %>%
            ggplot(aes(x=dia, y=favs)) +
            geom_bar(stat = "identity")+
            theme_light()+
            labs(title = "Favs por día de la semana ")
```

```{r}
tuits_df %>% mutate(dia = wday(created, label = TRUE)) %>%
            group_by(dia) %>% 
            summarise(favs = mean(favoriteCount)) %>%
            ggplot(aes(x=dia, y=favs)) +
            geom_bar(stat = "identity")+
            theme_light()+
            labs(title = "Promedio de favs por día de la semana ")
```

```{r}
tuits_df %>% mutate(hora = format(as.POSIXct(created,format="%H:%M:%S"
                                             ),"%H")) %>%
            group_by(hora) %>%
            summarise(favs=mean(favoriteCount))%>%
            ggplot(aes(x=hora, y=favs))+
            geom_point()+
            theme_light()+
            labs(title = "Promedio de favs por hora")
```

```{r}
tuits_df %>% mutate(hora = format(as.POSIXct(created,format="%H:%M:%S"),"%H"),
                    dia_sem = wday(created, label = T)) %>%
            group_by(hora, dia_sem) %>%
            summarise(favs=mean(favoriteCount))%>%
            ggplot(aes(x=hora, y=favs, color=dia_sem))+
            geom_point()+
            theme_light()+
            labs(title = "Promedio de favs por hora")
```

```{r}
tuits_corpus <- Corpus(VectorSource(tuits_df$text), 
                        readerControl = list(readPlain, language="sp", load=TRUE))
```

```{r}
tuits_corpus <- tm_map(tuits_corpus, content_transformer(tolower))
tuits_corpus <- tm_map(tuits_corpus, removePunctuation)
tuits_corpus <- tm_map(tuits_corpus, removeNumbers)
tuits_corpus <- tm_map(tuits_corpus, removeWords, stopwords("spanish"))
inspect(tuits_corpus[1:5])

subs <- function(s){
            s <- sub("¿", "", s)
            s <- sub("https*", "", s)
            return(s)
}

tuits_corpus <- tm_map(tuits_corpus, content_transformer(subs))
tuits_corpus <- tm_map(tuits_corpus, stripWhitespace)
inspect(tuits_corpus[1:5])
```

```{r}
tuits_dtm <- tokenize_ngrams(sapply(tuits_corpus, as.character), n=1)
tuits_dtm <- unlist(tuits_dtm)
tuits_dtm <- data.frame(table(tuits_dtm))
tuits_dtm <- arrange(tuits_dtm, desc(Freq))
head(tuits_dtm, 15)
```

```{r}
my_stopwords <- c("si", "d")
tuits_corpus <- tm_map(tuits_corpus, removeWords, my_stopwords)
tuits_corpus <- tm_map(tuits_corpus, stripWhitespace)
tuits_dtm <- tokenize_ngrams(sapply(tuits_corpus, as.character), n=1)
tuits_dtm <- unlist(tuits_dtm)
tuits_dtm <- data.frame(table(tuits_dtm))
tuits_dtm <- arrange(tuits_dtm, desc(Freq))
head(tuits_dtm, 15)
```

```{r}
colnames(tuits_dtm) <- c("word", "freq")
tuits_dtm$word <- as.character(tuits_dtm$word)
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "Palabras más frequentes")
wordcloud(words = tuits_dtm$word, freq = tuits_dtm$freq, 
          main ="Title", min.freq = 10,max.words = 200, 
          random.order = F, rot.per = 0.35,
          colors = brewer.pal(8, "Set1"),
          scale = c(2.5,0.7))
```

```{r}
my_stopwords <- c("si", "d", "diagramadeven", "esteusermurio", "comacurez", "elcancerend",
                  "jajajaja", "jejeje", "xd", "jajaja", "jeje", "c", "natszendro",
                  "ay", "fotoenpared", "elizarial", "iamthecat", "patriciagaso", 
                  "i", "s", "is","of", "jaja","claudifonos")
tuits_corpus <- tm_map(tuits_corpus, removeWords, my_stopwords)
tuits_corpus <- tm_map(tuits_corpus, stripWhitespace)
tuits_dtm <- tokenize_ngrams(sapply(tuits_corpus, as.character), n=1)
tuits_dtm <- unlist(tuits_dtm)
tuits_dtm <- data.frame(table(tuits_dtm))
tuits_dtm <- arrange(tuits_dtm, desc(Freq))
colnames(tuits_dtm) <- c("word", "freq")
tuits_dtm$word <- as.character(tuits_dtm$word)
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, "Palabras más frequentes")
wordcloud(words = tuits_dtm$word, freq = tuits_dtm$freq, 
          main ="Title", min.freq = 10,max.words = 200, 
          random.order = F, rot.per = 0.35,
          colors = brewer.pal(8, "Set2"),
          scale = c(2.5,0.7))
```

```{r}
tuits_df$texto_limpio <- sapply(tuits_corpus, as.character)
```

```{r}
tuits_df$matematicas <- grepl("matemáticas", tuits_df$texto_limpio)
tuits_df$python <- grepl("python", tuits_df$texto_limpio)
tuits_df$topologia <- grepl("topología", tuits_df$texto_limpio)
tuits_df$tesis <- grepl("tesis", tuits_df$texto_limpio)
tuits_df$crush <- grepl("crush", tuits_df$texto_limpio)
tuits_df$amor <- grepl("amor", tuits_df$texto_limpio)
```

```{r}
print("Estadísticas de los favs en tuits de matemáticas:")
summary(tuits_df$favoriteCount[tuits_df$matematicas])
print("Estadísticas de los favs en tuits de python:")
summary(tuits_df$favoriteCount[tuits_df$python])
print("Estadísticas de los favs en tuits de toplogía:")
summary(tuits_df$favoriteCount[tuits_df$topologia])
print("Estadísticas de los favs en tuits de tesis:")
summary(tuits_df$favoriteCount[tuits_df$tesis])
print("Estadísticas de los favs en tuits de crush:")
summary(tuits_df$favoriteCount[tuits_df$crush])
print("Estadísticas de los favs en tuits de amor")
summary(tuits_df$favoriteCount[tuits_df$amor])
```

